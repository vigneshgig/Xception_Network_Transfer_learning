{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "import keras\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = '/content/drive/My Drive/monogramdataset.hdf5'\n",
    "hdf5_pathtest = '/content/drive/My Drive/monogramdatasetvalidation.hdf5'\n",
    "\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "hdf5_filetest = h5py.File(hdf5_pathtest, \"r\")\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = hdf5_file.get('train_img').value\n",
    "y_train = hdf5_file.get('train_labels').value\n",
    "X_val  = hdf5_filetest.get('val_img').value\n",
    "y_val  = hdf5_filetest.get('val_labels').value\n",
    "X_test  = hdf5_filetest.get('test_img').value\n",
    "y_test  = hdf5_filetest.get('test_labels').value\n",
    "# X_train = X_train.reshape(X_train.shape[2],X_train.shape[1],X_train.shape[0])\n",
    "# X_test = X_test.reshape(X_test.shape[2],X_test.shape[1],X_test.shape[0])\n",
    "hdf5_file.close()\n",
    "X_train = X_train.reshape(X_train.shape[0], 299, 299,3).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 299, 299,3).astype('float32')\n",
    "X_val  = X_val.reshape(X_val.shape[0], 299, 299,3).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(X_train.shape[0], 299, 299,1).astype('float32')\n",
    "# X_test = X_test.reshape(X_test.shape[0], 299, 299,1).astype('float32')\n",
    "# X_val  = X_val.reshape(X_val.shape[0], 299, 299,1).astype('float32')\n",
    "\n",
    "# create base pre-trained model\n",
    "from keras.applications.xception import Xception\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "base_model = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "#add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(200,activation='elu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(170,activation='elu')(x)\n",
    "predictions = Dense(157,activation='hard_sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # we use SGD with a low learning rate\n",
    "from keras.optimizers import Nadam\n",
    "from keras.optimizers import adam\n",
    "model.compile(optimizer=Nadam(lr=0.0001), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# # alongside the top Dense layers\n",
    "# model.fit_generator(...)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val),shuffle=\"batch\" ,epochs=10, batch_size=10,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0,batch_size=10)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "# # serialize model to JSON\n",
    "try:\n",
    "    model_json = model.to_json()\n",
    "    with open(\"/content/drive/My Drive/monogrammodelxceptioneludrop299.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "except:\n",
    "    pass\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/content/drive/My Drive/monogrammodelxceptioneludrop299.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the image and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.optimizers import adam\n",
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = u'/content/drive/My Drive/monogramcleaning.hdf5'\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "X_pattern = hdf5_file.get('monogram_img').value\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('/content/drive/My Drive/patternmodelnasnetdrop299.json')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"/content/drive/My Drive/patternmodelnasnetdrop299.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer=adam(lr=0.00008), loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  prediction = loaded_model.predict(X_pattern,batch_size=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/content/drive/My Drive/prediction_monogram.npy',prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
