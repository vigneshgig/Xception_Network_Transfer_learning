{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "52\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Monogram']\n",
      "157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de86033275144a8aaaa43a55268106c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=65), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# alphabet = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "#            'a','b','c','d']\n",
    "alphabet  = [chr(i) for i in range(65,91)]\n",
    "small_alphabet = [chr(i) for i in range(97,123)]\n",
    "print(alphabet)\n",
    "print(small_alphabet)\n",
    "alphabet += small_alphabet\n",
    "print(len(alphabet))\n",
    "labels = alphabet * 3 +  ['Monogram']\n",
    "print(labels)\n",
    "print(len(labels))\n",
    "monogram = list(glob.glob('D:\\\\aidelete\\\\monogram\\\\validation\\\\monograms\\\\*.*'))\n",
    "\n",
    "monogramall_label = []\n",
    "for path in tqdm(monogram):\n",
    "    monogram_label = [0 for i in labels]\n",
    "    monogram_label[-1] = 1\n",
    "    file_name = os.path.basename(path)\n",
    "    file_name = file_name[:-4]\n",
    "    file_name = file_name[-3:]\n",
    "    file_name = re.sub(r'[^A-Za-z]','',file_name)\n",
    "\n",
    "    for k,check in enumerate(file_name):\n",
    "        if k == 0:\n",
    "            monogram_label[labels[:52].index(check)] = 1\n",
    "        elif k == 1:\n",
    "            monogram_label[52+labels[52:52+52].index(check)] = 1\n",
    "        elif k == 2:\n",
    "            monogram_label[52+52+labels[52+52:].index(check)] = 1\n",
    "    \n",
    "    monogramall_label.append(monogram_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notamonogram = list(glob.glob('D:\\\\aidelete\\\\monogram\\\\validation\\\\notmonograms\\\\*.*'))\n",
    "# pattern     = list(glob.glob('D:\\\\aidelete\\\\corner\\\\corners\\\\*.*'))\n",
    "not_labels = []\n",
    "for i in notamonogram:\n",
    "    not_labels.append([0 for path in labels])\n",
    "# for path in pattern:\n",
    "#     labels.append(1)\n",
    "addrs =  copy(notamonogram)\n",
    "addrs.extend(monogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "labels.extend(not_labels)\n",
    "labels.extend(monogramall_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notapattern = list(glob.glob('D:\\\\aidelete\\\\corner\\\\validation_test\\\\notcorners\\\\*.*'))\n",
    "# pattern     = list(glob.glob('D:\\\\aidelete\\\\corner\\\\validation_test\\\\corners\\\\*.*'))\n",
    "\n",
    "# labels = [0 for path in notapattern]\n",
    "# for path in pattern:\n",
    "#     labels.append(1)\n",
    "# addrs =  copy(notapattern)\n",
    "# addrs.extend(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in  addrs:\n",
    "    d = u'\\\\\\\\?\\\\'+i\n",
    "#     try:\n",
    "    with open(d,'rb') as f:\n",
    "        pass\n",
    "#     except FileNotFoundError:\n",
    "#         addrs.remove(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(addrs, labels))\n",
    "shuffle(data)\n",
    "shuffle(data)\n",
    "shuffle(data)\n",
    "addrs, labels = zip(*data)\n",
    "\n",
    "# Divide the hata into 60% train, 20% validation, and 20% test\n",
    "# train_addrs = addrs[0:int(1*len(addrs))]\n",
    "# train_labels = labels[0:int(1*len(labels))]\n",
    "val_addrs = addrs[0:int(0.8*len(addrs))]\n",
    "val_labels = labels[0:int(0.8*len(addrs))]\n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "data_order = 'tf'  # 'th' for Theano, 'tf' for Tensorflow\n",
    "# check the order of data and chose proper data shape to save images\n",
    "hdf5_path = u'D:/aidelete/monogram/monogramdatasetvalidation.hdf5'\n",
    "if data_order == 'th':\n",
    "    train_shape = (len(train_addrs), 3, 100, 100)\n",
    "    val_shape = (len(val_addrs), 3, 100, 100)\n",
    "    test_shape = (len(test_addrs), 3, 100, 100)\n",
    "elif data_order == 'tf':\n",
    "#     train_shape = (len(train_addrs), 299, 299,3)\n",
    "    val_shape = (len(val_addrs), 299, 299,3)\n",
    "    test_shape = (len(test_addrs), 299, 299,3)\n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "# hdf5_file.create_dataset(\"train_img\", train_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"val_img\", val_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"test_img\", test_shape, np.int8)\n",
    "# hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "# hdf5_file.create_dataset(\"train_labels\", (len(train_addrs),), np.int8)\n",
    "# hdf5_file[\"train_labels\"][...] = train_labels\n",
    "hdf5_file.create_dataset(\"val_labels\", (len(val_addrs),157), np.int8)\n",
    "hdf5_file[\"val_labels\"][...] = val_labels\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_addrs),157), np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels\n",
    "# hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "# a numpy array to save the mean of the images\n",
    "# mean = np.zeros(train_shape[1:], np.float32)\n",
    "# loop over train addresses\n",
    "# for i in range(len(train_addrs)):\n",
    "#     # print how many images are saved every 1000 images\n",
    "#     if i % 1000 == 0 and i > 1:\n",
    "#         print ('Train data: {}/{}'.format(i, len(train_addrs)))\n",
    "#     # read an image and resize to (100, 100)\n",
    "#     # cv2 load images as BGR, convert it to RGB\n",
    "#     addr = train_addrs[i]\n",
    "#     try:\n",
    "#         img = cv2.imread(addr)\n",
    "#         img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         img = img.reshape(299,299,1)\n",
    "#     except:\n",
    "#         addr = u'\\\\\\\\?\\\\' + addr\n",
    "#         try:\n",
    "#             img =  mpimg.imread(addr)\n",
    "#             img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "# #         img = img.reshape(299,299,1)\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         except:\n",
    "#             img =  color.gray2rgb(mpimg.imread(addr))\n",
    "#             img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "# #         img = img.reshape(299,299,1)\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     # add any image pre-processing here\n",
    "#     # if the data order is Theano, axis orders should change\n",
    "#     if data_order == 'th':\n",
    "#         img = np.rollaxis(img, 2)\n",
    "#     # save the image and calculate the mean so far\n",
    "#     hdf5_file[\"train_img\"][i, ...] = img[None]\n",
    "#     mean += img / float(len(train_labels))\n",
    "# loop over validation addresses\n",
    "for i in range(len(val_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Validation data: {}/{}'.format(i, len(val_addrs)))\n",
    "    # read an image and resize to (100, 100)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    try:\n",
    "        addr = val_addrs[i]\n",
    "        img = cv2.imread(addr)\n",
    "        img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         img = img.reshape(299,299,1)\n",
    "    except:\n",
    "        addr = u'\\\\\\\\?\\\\' + addr\n",
    "        try:\n",
    "            img =  mpimg.imread(addr)\n",
    "            img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "#         img = img.reshape(299,299,1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            img =  color.gray2rgb(mpimg.imread(addr))\n",
    "            img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "#         img = img.reshape(299,299,1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         print(addr)\n",
    "#     add any image pre-processing here\n",
    "#     if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "    # save the image\n",
    "    hdf5_file[\"val_img\"][i, ...] = img[None]\n",
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if i % 1000 == 0 and i > 1:\n",
    "        print ('Test data: {}/{}'.format(i, len(test_addrs)))\n",
    "    # read an image and resize to (100, 100)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    try:\n",
    "        img = cv2.imread(addr)\n",
    "        img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         img = img.reshape(299,299,1)\n",
    "    except:\n",
    "        addr = u'\\\\\\\\?\\\\' + addr\n",
    "        try:\n",
    "            img =  mpimg.imread(addr)\n",
    "            img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "#         img = img.reshape(299,299,1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            img =  color.gray2rgb(mpimg.imread(addr))\n",
    "            img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         img = img.reshape(299,299,1)\n",
    "#         print(addr)\n",
    "#     add any image pre-processing here\n",
    "#     if the data order is Theano, axis orders should change\n",
    "    if data_order == 'th':\n",
    "        img = np.rollaxis(img, 2)\n",
    "#     save the image\n",
    "    hdf5_file[\"test_img\"][i, ...] = img[None]\n",
    "# save the mean and close the hdf5 file\n",
    "# hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_img', 'test_labels', 'val_img', 'val_labels']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "# images = hdf5_file.rotrain_img[:]\n",
    "list(hdf5_file.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
